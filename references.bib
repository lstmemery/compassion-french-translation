
@book{mair_modern_2018,
	title = {Modern psychometrics with {R}},
	isbn = {978-3-319-93175-3},
	language = {English},
	author = {Mair, Patrick},
	year = {2018},
	note = {OCLC: 1057679511},
	file = {Mair_2018_Modern psychometrics with R.pdf:/home/deadhand/Zotero/storage/UX3TQNVX/Mair_2018_Modern psychometrics with R.pdf:application/pdf},
}

@article{gilbert_development_2017,
	title = {The development of compassionate engagement and action scales for self and others},
	volume = {4},
	issn = {2053-2393},
	url = {https://doi.org/10.1186/s40639-017-0033-3},
	doi = {10.1186/s40639-017-0033-3},
	abstract = {Studies of the value of compassion on physical and mental health and social relationships have proliferated in the last 25 years. Although, there are several conceptualisations and measures of compassion, this study develops three new measures of compassion competencies derived from an evolutionary, motivational approach. The scales assess 1. the compassion we experience for others, 2. the compassion we experience from others, and 3. self-compassion based on a standard definition of compassion as a ‘sensitivity to suffering in self and others with a commitment to try to alleviate and prevent it’. We explored these in relationship to other compassion scales, self-criticism, depression, anxiety, stress and well-being.},
	number = {1},
	urldate = {2021-11-13},
	journal = {Journal of Compassionate Health Care},
	author = {Gilbert, Paul and Catarino, Francisca and Duarte, Cristiana and Matos, Marcela and Kolts, Russell and Stubbs, James and Ceresatto, Laura and Duarte, Joana and Pinto-Gouveia, José and Basran, Jaskaran},
	month = apr,
	year = {2017},
	keywords = {Confirmatory Factor Analysis, Depressive Symptom, Distress Tolerance, Exploratory Factor Analysis, Perspective Taking},
	pages = {4},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/YK8J554X/Gilbert et al. - 2017 - The development of compassionate engagement and ac.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/DRJ5UUXQ/s40639-017-0033-3.html:text/html},
}

@article{gu_development_2020,
	title = {Development and {Psychometric} {Properties} of the {Sussex}-{Oxford} {Compassion} {Scales} ({SOCS})},
	volume = {27},
	issn = {1552-3489},
	doi = {10.1177/1073191119860911},
	abstract = {Compassion has received increasing societal and scientific interest in recent years. The science of compassion requires a tool that can offer valid and reliable measurement of the construct to allow examination of its causes, correlates, and consequences. The current studies developed and examined the psychometric properties of new self-report measures of compassion for others and for the self, the 20-item Sussex-Oxford Compassion for Others Scale (SOCS-O) and 20-item Sussex-Oxford Compassion for the Self Scale (SOCS-S). These were based on the theoretically and empirically supported definition of compassion as comprising five dimensions: (a) recognizing suffering, (b) understanding the universality of suffering, (c) feeling for the person suffering, (d) tolerating uncomfortable feelings, and (e) motivation to act/acting to alleviate suffering. Findings support the five-factor structure for both the SOCS-O and SOCS-S. Scores on both scales showed adequate internal consistency, interpretability, floor/ceiling effects, and convergent and discriminant validity.},
	language = {eng},
	number = {1},
	journal = {Assessment},
	author = {Gu, Jenny and Baer, Ruth and Cavanagh, Kate and Kuyken, Willem and Strauss, Clara},
	month = jan,
	year = {2020},
	pmid = {31353931},
	pmcid = {PMC6906538},
	keywords = {Humans, Female, Male, Adult, compassion, Empathy, Factor Analysis, Statistical, measure, Middle Aged, Psychometrics, questionnaire, Reproducibility of Results, Self Report, self-compassion, self-report, SOCS-O, SOCS-S, Surveys and Questionnaires},
	pages = {3--20},
	file = {Full Text:/home/deadhand/Zotero/storage/DZJSSS7B/Gu et al. - 2020 - Development and Psychometric Properties of the Sus.pdf:application/pdf},
}

@article{baumsteiger_measuring_2019,
	title = {Measuring {Prosociality}: {The} {Development} of a {Prosocial} {Behavioral} {Intentions} {Scale}},
	volume = {101},
	issn = {1532-7752},
	shorttitle = {Measuring {Prosociality}},
	doi = {10.1080/00223891.2017.1411918},
	abstract = {Prosociality is a critical issue in behavioral research. In this investigation, we developed a measure of prosocial behavioral intentions. Qualitative responses from two surveys (n = 465) and items from existing measures were used to generate a list of prosocial behaviors in which people might intend to engage. We factor analyzed responses to these items (n = 319) and retained the most common and representative items. The new measure demonstrated adequate internal consistency (n = 247, 147; α = .81, .83); convergent validity with past prosocial behavior (r = .51, .43), moral identity (r = .50, .55), and materialism (r = -.30, -.20). The instrument also predicted prosocial behavior while controlling for a prior measure of prosocial intentions, Exp(B) = 1.99, Wald = 10.59, p = .001, thereby demonstrating incremental predictive validity. This 4-item scale could be used across contexts to advance the study of prosociality.},
	language = {eng},
	number = {3},
	journal = {Journal of Personality Assessment},
	author = {Baumsteiger, Rachel and Siegel, Jason T.},
	month = jun,
	year = {2019},
	pmid = {29448814},
	keywords = {Humans, Female, Male, Adult, Factor Analysis, Statistical, Psychometrics, Surveys and Questionnaires, Intention, Morals, Self Efficacy, Self-Control, Social Behavior},
	pages = {305--314},
}

@article{neff_examining_2019,
	title = {Examining the factor structure of the {Self}-{Compassion} {Scale} in 20 diverse samples: {Support} for use of a total score and six subscale scores},
	volume = {31},
	issn = {1939-134X},
	shorttitle = {Examining the factor structure of the {Self}-{Compassion} {Scale} in 20 diverse samples},
	doi = {10.1037/pas0000629},
	abstract = {This study examined the factor structure of the Self-Compassion Scale (SCS) using secondary data drawn from 20 samples (N = 11,685)-7 English and 13 non-English-including 10 community, 6 student, 1 mixed community/student, 1 meditator, and 2 clinical samples. Self-compassion is theorized to represent a system with 6 constituent components: self-kindness, common humanity, mindfulness and reduced self-judgment, isolation and overidentification. There has been controversy as to whether a total score on the SCS or if separate scores representing compassionate versus uncompassionate self-responding should be used. The current study examined the factor structure of the SCS using confirmatory factor analyses (CFA) and Exploratory Structural Equation Modeling (ESEM) to examine 5 distinct models: 1-factor, 2-factor correlated, 6-factor correlated, single-bifactor (1 general self-compassion factor and 6 group factors), and 2-bifactor models (2 correlated general factors each with 3 group factors representing compassionate or uncompassionate self-responding). Results indicated that a 1- and 2-factor solution to the SCS had inadequate fit in every sample examined using both CFA and ESEM, whereas fit was excellent using ESEM for the 6-factor correlated, single-bifactor and correlated 2-bifactor models. However, factor loadings for the correlated 2-bifactor models indicated that 2 separate factors were not well specified. A general factor explained 95\% of the reliable item variance in the single-bifactor model. Results support use of the SCS to examine 6 subscale scores (representing the constituent components of self-compassion) or a total score (representing overall self-compassion), but not separate scores representing compassionate and uncompassionate self-responding. (PsycINFO Database Record (c) 2018 APA, all rights reserved).},
	language = {eng},
	number = {1},
	journal = {Psychological Assessment},
	author = {Neff, Kristin D. and Tóth-Király, István and Yarnell, Lisa M. and Arimitsu, Kohki and Castilho, Paula and Ghorbani, Nima and Guo, Hailan Xiaoxia and Hirsch, Jameson K. and Hupfeld, Jörg and Hutz, Claudio S. and Kotsou, Ilios and Lee, Woo Kyeong and Montero-Marin, Jesus and Sirois, Fuschia M. and de Souza, Luciana K. and Svendsen, Julie L. and Wilkinson, Ross B. and Mantzios, Michail},
	month = jan,
	year = {2019},
	pmid = {30124303},
	keywords = {Humans, Female, Male, Adult, Empathy, Factor Analysis, Statistical, Middle Aged, Psychometrics, Adolescent, Aged, Aged, 80 and over, Self Concept, Young Adult},
	pages = {27--45},
	file = {Accepted Version:/home/deadhand/Zotero/storage/LTK74887/Neff et al. - 2019 - Examining the factor structure of the Self-Compass.pdf:application/pdf},
}

@article{lafontaine_selecting_2016,
	title = {Selecting the best items for a short-form of the {Experiences} in {Close} {Relationships} questionnaire},
	volume = {32},
	issn = {2151-2426},
	doi = {10.1027/1015-5759/a000243},
	abstract = {Five studies were conducted to develop a short form of the Experiences in Close Relationships (ECR) questionnaire with optimal psychometric properties. Study 1 involved Item Response Theory (IRT) analyses of the responses of 2,066 adults, resulting in a 12-item form of the ECR containing the most discriminating items. The psychometric properties of the ECR-12 were further demonstrated in two longitudinal studies of community samples of couples (Studies 2 and 3), in a sample of individuals in same-sex relationships (Study 4), and with couples seeking therapy (Study 5). The psychometric properties of the ECR-12 are as good as those of the original ECR and superior to those of an existing short form. The ECR-12 can confidently be used by researchers and mental health practitioners when a short measure of attachment anxiety and avoidance is required. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {European Journal of Psychological Assessment},
	author = {Lafontaine, Marie-France and Brassard, Audrey and Lussier, Yvan and Valois, Pierre and Shaver, Philip R. and Johnson, Susan M.},
	year = {2016},
	note = {Place: Germany
Publisher: Hogrefe Publishing},
	keywords = {Psychometrics, Anxiety, Attachment Behavior, Avoidance, Interpersonal Relationships, Self-Report, Test Construction, Test Forms},
	pages = {140--154},
	file = {Snapshot:/home/deadhand/Zotero/storage/EWJ5FMNS/2015-09100-001.html:text/html},
}

@article{neff_relationship_2013,
	title = {The {Relationship} between {Self}-compassion and {Other}-focused {Concern} among {College} {Undergraduates}, {Community} {Adults}, and {Practicing} {Meditators}},
	volume = {12},
	issn = {1529-8868},
	url = {https://doi.org/10.1080/15298868.2011.649546},
	doi = {10.1080/15298868.2011.649546},
	abstract = {The present study examined the link between self-compassion and concern for the well-being of others. Other-focused concern variables included compassion for humanity, empathetic concern, perspective taking, personal distress, altruism and forgiveness. Participants included 384 college undergraduates, 400 community adults, and 172 practicing meditators. Among all participant groups, higher levels of self-compassion were significantly linked to more perspective taking, less personal distress, and greater forgiveness. Self-compassion was linked to compassion for humanity, empathetic concern, and altruism among community adults and meditators but not college undergraduates. The strength of the association between self-compassion and other-focused concern also varied according to participant group and gender. The strongest links tended to be found among meditators, while women tended to show weaker associations than men.},
	number = {2},
	urldate = {2021-11-13},
	journal = {Self and Identity},
	author = {Neff, Kristin D. and Pommier, Elizabeth},
	month = mar,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15298868.2011.649546},
	keywords = {Empathy, Altruism, Compassion, Forgiveness, Prosocial behavior, Self-compassion},
	pages = {160--176},
	file = {Snapshot:/home/deadhand/Zotero/storage/LH9Q92HR/15298868.2011.html:text/html;The Relationship between Self-compassion and Other-focused Concern among College Undergraduates, Community Adults, and Practicing Meditators:/home/deadhand/Zotero/storage/VDD7X8WA/neff2013.pdf.pdf:application/pdf},
}

@phdthesis{pommier_compassion_2010,
	type = {thesis},
	title = {The {Compassion} {Scale}},
	url = {https://repositories.lib.utexas.edu/handle/2152/ETD-UT-2010-12-2213},
	abstract = {These studies define a Buddhist conceptualization of compassion and describe the development of the Compassion Scale. The definition of compassion was adopted from Neff's (2003) model of self-compassion that proposes that the construct entails kindness, common humanity, and mindfulness. The six-factor structure was adopted from the Self-Compassion Scale (2003) representing positively and negatively worded items of the three components proposed to entail compassion. The six-factors for compassion are named: kindness vs. indifference, common humanity vs. separation, and mindfulness vs. disengagement. Study 1 was conducted to provide support for content validity. Study 2 was conducted to provide initial validation for the scale. Study 3 was conducted to cross-validate findings from the second study. Results provide evidence for the structure of the scale. Cronbach's alpha and split-half estimates suggest good reliability for both samples. Compassion was significantly correlated with compassionate love, wisdom, social connectedness, and empathy providing support for convergent validity. Factor analysis in both samples indicated good fit using Hu \& Bentler (1998) criteria. Results suggest that the Compassion Scale is a psychometrically sound measure of compassion. Given that Buddhist concepts of compassion are receiving increased attention in psychology (e.g. Davidson, 2006; Gilbert, 2005, Goetz, 2010) this scale will hopefully prove useful in research that examines compassion from a non-Western perspective.},
	language = {eng},
	urldate = {2021-11-13},
	author = {Pommier, Elizabeth Ann},
	month = dec,
	year = {2010},
	note = {Accepted: 2011-02-09T17:48:05Z},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/7PG3VXRT/Pommier - 2010 - The Compassion Scale.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/W3T8DRFP/ETD-UT-2010-12-2213.html:text/html},
}

@article{pommier_development_2020,
	title = {The {Development} and {Validation} of the {Compassion} {Scale}},
	volume = {27},
	issn = {1552-3489},
	doi = {10.1177/1073191119874108},
	abstract = {This article presents a measure of compassion for others called the Compassion Scale (CS), which is based on Neff's theoretical model of self-compassion. Compassion was operationalized as experiencing kindness, a sense of common humanity, mindfulness, and lessened indifference toward the suffering of others. Study 1 (n = 465) describes the development of potential scale items and the final 16 CS items chosen based on results from analyses using bifactor exploratory structural equation modeling. Study 2 (n = 510) cross-validates the CS in a second student sample. Study 3 (n = 80) establishes test-retest reliability. Study 4 (n = 1,394) replicates results with a community sample, while Study 5 (n = 172) replicates results with a sample of meditators. Study 6 (n = 913) examines the finalized version of the CS in a community sample. Evidence regarding reliability, discriminant, convergent, construct, and known-groups validity for the CS is provided.},
	language = {eng},
	number = {1},
	journal = {Assessment},
	author = {Pommier, Elizabeth and Neff, Kristin D. and Tóth-Király, István},
	month = jan,
	year = {2020},
	pmid = {31516024},
	keywords = {Humans, Female, Male, United States, Adult, compassion, Empathy, Factor Analysis, Statistical, Middle Aged, Psychometrics, Reproducibility of Results, self-compassion, Surveys and Questionnaires, Self Concept, Young Adult, bifactor analyses, Community Participation, Compassion Scale, exploratory structural equation modeling, Mindfulness, Self-Compassion Scale, Students, Universities},
	pages = {21--39},
}

@article{terwee_quality_2007,
	title = {Quality criteria were proposed for measurement properties of health status questionnaires},
	volume = {60},
	issn = {0895-4356},
	doi = {10.1016/j.jclinepi.2006.03.012},
	abstract = {OBJECTIVES: Recently, an increasing number of systematic reviews have been published in which the measurement properties of health status questionnaires are compared. For a meaningful comparison, quality criteria for measurement properties are needed. Our aim was to develop quality criteria for design, methods, and outcomes of studies on the development and evaluation of health status questionnaires.
STUDY DESIGN AND SETTING: Quality criteria for content validity, internal consistency, criterion validity, construct validity, reproducibility, longitudinal validity, responsiveness, floor and ceiling effects, and interpretability were derived from existing guidelines and consensus within our research group.
RESULTS: For each measurement property a criterion was defined for a positive, negative, or indeterminate rating, depending on the design, methods, and outcomes of the validation study.
CONCLUSION: Our criteria make a substantial contribution toward defining explicit quality criteria for measurement properties of health status questionnaires. Our criteria can be used in systematic reviews of health status questionnaires, to detect shortcomings and gaps in knowledge of measurement properties, and to design validation studies. The future challenge will be to refine and complete the criteria and to reach broad consensus, especially on quality criteria for good measurement properties.},
	language = {eng},
	number = {1},
	journal = {Journal of Clinical Epidemiology},
	author = {Terwee, Caroline B. and Bot, Sandra D. M. and de Boer, Michael R. and van der Windt, Daniëlle A. W. M. and Knol, Dirk L. and Dekker, Joost and Bouter, Lex M. and de Vet, Henrica C. W.},
	month = jan,
	year = {2007},
	pmid = {17161752},
	keywords = {Humans, Research Design, Psychometrics, Reproducibility of Results, Surveys and Questionnaires, Evaluation Studies as Topic, Health Status Indicators, Review Literature as Topic},
	pages = {34--42},
	file = {Full Text:/home/deadhand/Zotero/storage/LHE6KNYG/Terwee et al. - 2007 - Quality criteria were proposed for measurement pro.pdf:application/pdf},
}

@article{kung_are_2018,
	title = {Are {Attention} {Check} {Questions} a {Threat} to {Scale} {Validity}?},
	volume = {67},
	issn = {1464-0597},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/apps.12108},
	doi = {10.1111/apps.12108},
	abstract = {Attention checks have become increasingly popular in survey research as a means to filter out careless respondents. Despite their widespread use, little research has empirically tested the impact of attention checks on scale validity. In fact, because attention checks can induce a more deliberative mindset in survey respondents, they may change the way respondents answer survey questions, posing a threat to scale validity. In two studies, we tested this hypothesis (N = 816). We examined whether common attention checks—instructed-response items (Study 1) and an instructional manipulation check (Study 2)—impact responses to a well-validated management scale. Results showed no evidence that they affect scale validity, both in reported scale means and tests of measurement invariance. These findings allow researchers to justify the use of attention checks without compromising scale validity and encourage future research to examine other survey characteristic-respondent dynamics to advance our use of survey methods.},
	language = {en},
	number = {2},
	urldate = {2021-11-20},
	journal = {Applied Psychology},
	author = {Kung, Franki Y.H. and Kwok, Navio and Brown, Douglas J.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/apps.12108},
	pages = {264--283},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/JN2CXKFE/Kung et al. - 2018 - Are Attention Check Questions a Threat to Scale Va.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/TTBPZ9AL/apps.html:text/html},
}

@misc{noauthor_wlsmv_nodate,
	title = {{WLSMV} or {DWLS}? {Lavaan} and {SEM} with categorical variables},
	url = {https://groups.google.com/g/lavaan/c/Nymu7jmVUk8},
	urldate = {2021-11-27},
	file = {WLSMV or DWLS? Lavaan and SEM with categorical variables:/home/deadhand/Zotero/storage/EWU7N2FY/Nymu7jmVUk8.html:text/html},
}

@article{honaker_amelia_2011,
	title = {Amelia {II}: {A} {Program} for {Missing} {Data}},
	volume = {45},
	copyright = {Copyright (c) 2009 James Honaker, Gary King, Matthew Blackwell},
	issn = {1548-7660},
	shorttitle = {Amelia {II}},
	url = {https://doi.org/10.18637/jss.v045.i07},
	doi = {10.18637/jss.v045.i07},
	abstract = {Amelia II is a complete R package for multiple imputation of missing data. The package implements a new expectation-maximization with bootstrapping algorithm that works faster, with larger numbers of variables, and is far easier to use, than various Markov chain Monte Carlo approaches, but gives essentially the same answers. The program also improves imputation models by allowing researchers to put Bayesian priors on individual cell values, thereby including a great deal of potentially valuable and extensive information. It also includes features to accurately impute cross-sectional datasets, individual time series, or sets of time series for different cross-sections. A full set of graphical diagnostics are also available. The program is easy to use, and the simplicity of the algorithm makes it far more robust; both a simple command line and extensive graphical user interface are included.},
	language = {en},
	urldate = {2021-11-27},
	journal = {Journal of Statistical Software},
	author = {Honaker, James and King, Gary and Blackwell, Matthew},
	month = dec,
	year = {2011},
	pages = {1--47},
	file = {Full Text:/home/deadhand/Zotero/storage/VIWD8F2L/Honaker et al. - 2011 - Amelia II A Program for Missing Data.pdf:application/pdf},
}

@article{proitsi_multiple_2011,
	title = {A {Multiple} {Indicators} {Multiple} {Causes} ({MIMIC}) model of {Behavioural} and {Psychological} {Symptoms} in {Dementia} ({BPSD})},
	volume = {32},
	issn = {1558-1497},
	doi = {10.1016/j.neurobiolaging.2009.03.005},
	abstract = {INTRODUCTION: Although there is evidence for distinct behavioural sub-phenotypes in Alzheimer's disease (AD), their inter-relationships and the effect of clinical variables on their expression have been little investigated.
METHODS: We have analysed a sample of 1850 probable AD patients from the UK and Greece with 10 item Neuropsychiatric Inventory (NPI) data. We applied a Multiple Indicators Multiple Causes (MIMIC) approach to investigate the effect of MMSE, disease duration, gender, age and age of onset on the structure of a four-factor model consisting of "psychosis", "moods", "agitation" and "behavioural dyscontrol".
RESULTS: Specific clinical variables predicted the expression of individual factors. When the inter-relationship of factors is modelled, some previously significant associations are lost. For example, lower MMSE scores predict psychosis, agitation and behavioural dyscontrol factors, but psychosis and mood predict the agitation factor. Taking these associations into account MMSE scores did not predict agitation.
CONCLUSIONS: The complexity of the inter-relations between symptoms, factors and clinical variables is efficiently captured by this MIMIC model.},
	language = {eng},
	number = {3},
	journal = {Neurobiology of Aging},
	author = {Proitsi, P. and Hamilton, G. and Tsolaki, M. and Lupton, M. and Daniilidou, M. and Hollingworth, P. and Archer, N. and Foy, C. and Stylios, F. and McGuinness, B. and Todd, S. and Lawlor, B. and Gill, M. and Brayne, C. and Rubinsztein, D. C. and Owen, M. and Williams, J. and Craig, D. and Passmore, P. and Lovestone, S. and Powell, J. F.},
	month = mar,
	year = {2011},
	pmid = {19386383},
	keywords = {Humans, Female, Male, Factor Analysis, Statistical, Middle Aged, Aged, Aged, 80 and over, Cohort Studies, Dementia, Greece, Mental Disorders, Mental Status Schedule, Models, Statistical, Psychomotor Agitation, Psychotic Disorders},
	pages = {434--442},
}

@article{li_confirmatory_2016,
	title = {Confirmatory factor analysis with ordinal data: {Comparing} robust maximum likelihood and diagonally weighted least squares},
	volume = {48},
	issn = {1554-3528},
	shorttitle = {Confirmatory factor analysis with ordinal data},
	url = {https://doi.org/10.3758/s13428-015-0619-7},
	doi = {10.3758/s13428-015-0619-7},
	abstract = {In confirmatory factor analysis (CFA), the use of maximum likelihood (ML) assumes that the observed indicators follow a continuous and multivariate normal distribution, which is not appropriate for ordinal observed variables. Robust ML (MLR) has been introduced into CFA models when this normality assumption is slightly or moderately violated. Diagonally weighted least squares (WLSMV), on the other hand, is specifically designed for ordinal data. Although WLSMV makes no distributional assumptions about the observed variables, a normal latent distribution underlying each observed categorical variable is instead assumed. A Monte Carlo simulation was carried out to compare the effects of different configurations of latent response distributions, numbers of categories, and sample sizes on model parameter estimates, standard errors, and chi-square test statistics in a correlated two-factor model. The results showed that WLSMV was less biased and more accurate than MLR in estimating the factor loadings across nearly every condition. However, WLSMV yielded moderate overestimation of the interfactor correlations when the sample size was small or/and when the latent distributions were moderately nonnormal. With respect to standard error estimates of the factor loadings and the interfactor correlations, MLR outperformed WLSMV when the latent distributions were nonnormal with a small sample size of N = 200. Finally, the proposed model tended to be over-rejected by chi-square test statistics under both MLR and WLSMV in the condition of small sample size N = 200.},
	language = {en},
	number = {3},
	urldate = {2021-11-28},
	journal = {Behavior Research Methods},
	author = {Li, Cheng-Hsien},
	month = sep,
	year = {2016},
	pages = {936--949},
	file = {Springer Full Text PDF:/home/deadhand/Zotero/storage/M95E8DE8/Li - 2016 - Confirmatory factor analysis with ordinal data Co.pdf:application/pdf},
}

@article{flora_empirical_2004,
	title = {An {Empirical} {Evaluation} of {Alternative} {Methods} of {Estimation} for {Confirmatory} {Factor} {Analysis} {With} {Ordinal} {Data}},
	volume = {9},
	issn = {1082-989X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3153362/},
	doi = {10.1037/1082-989X.9.4.466},
	abstract = {Confirmatory factor analysis (CFA) is widely used for examining hypothesized relations among ordinal variables (e.g., Likert-type items). A theoretically appropriate method fits the CFA model to polychoric correlations using either weighted least squares (WLS) or robust WLS. Importantly, this approach assumes that a continuous, normal latent process determines each observed variable. The extent to which violations of this assumption undermine CFA estimation is not well-known. In this article, the authors empirically study this issue using a computer simulation study. The results suggest that estimation of polychoric correlations is robust to modest violations of underlying normality. Further, WLS performed adequately only at the largest sample size but led to substantial estimation difficulties with smaller samples. Finally, robust WLS performed well across all conditions.},
	number = {4},
	urldate = {2021-11-28},
	journal = {Psychological methods},
	author = {Flora, David B. and Curran, Patrick J.},
	month = dec,
	year = {2004},
	pmid = {15598100},
	pmcid = {PMC3153362},
	pages = {466--491},
	file = {PubMed Central Full Text PDF:/home/deadhand/Zotero/storage/GUXBPPSQ/Flora and Curran - 2004 - An Empirical Evaluation of Alternative Methods of .pdf:application/pdf},
}

@misc{noauthor_when_nodate,
	title = {When can categorical variables be treated as continuous? {A} comparison of robust continuous and categorical {SEM} estimation methods under suboptimal conditions. - {PsycNET}},
	shorttitle = {When can categorical variables be treated as continuous?},
	url = {https://doi.apa.org/record/2012-18631-001?doi=1},
	abstract = {A simulation study compared the performance of robust normal theory maximum likelihood (ML) and robust categorical least squares (cat-LS) methodology for estimating confirmatory factor analysis models with ordinal variables. Data were generated from 2 models with 2–7 categories, 4 sample sizes, 2 latent distributions, and 5 patterns of category thresholds. Results revealed that factor loadings and robust standard errors were generally most accurately estimated using cat-LS, especially with fewer than 5 categories; however, factor correlations and model fit were assessed equally well with ML. Cat-LS was found to be more sensitive to sample size and to violations of the assumption of normality of the underlying continuous variables. Normal theory ML was found to be more sensitive to asymmetric category thresholds and was especially biased when estimating large factor loadings. Accordingly, we recommend cat-LS for data sets containing variables with fewer than 5 categories and ML when there are 5 or more categories, sample size is small, and category thresholds are approximately symmetric. With 6–7 categories, results were similar across methods for many conditions; in these cases, either method is acceptable. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	language = {en},
	urldate = {2021-11-28},
	journal = {APA PsycNET},
	doi = {10.1037/a0029315},
	file = {Snapshot:/home/deadhand/Zotero/storage/3WHIYAM3/2012-18631-001.html:text/html},
}

@misc{noauthor_structural_nodate,
	title = {Structural {Equation} {Modeling} with lavaan {\textbar} {Wiley}},
	url = {https://www.wiley.com/en-us/Structural+Equation+Modeling+with+lavaan-p-9781119578994},
	abstract = {This book presents an introduction to structural equation modeling (SEM) and facilitates the access of students and researchers in various scientific fields to this powerful statistical tool. It offers a didactic initiation to SEM as well as to the open-source software, lavaan, and the rich and comprehensive technical features it offers. Structural Equation Modeling with lavaan thus helps the reader to gain autonomy in the use of SEM to test path models and dyadic models, perform confirmatory factor analyses and estimate more complex models such as general structural models with latent variables and latent growth models. SEM is approached both from the point of view of its process (i.e. the different stages of its use) and from the point of view of its product (i.e. the results it generates and their reading).},
	language = {en-us},
	urldate = {2021-11-28},
	journal = {Wiley.com},
	file = {Snapshot:/home/deadhand/Zotero/storage/7SZ8D3TG/Structural+Equation+Modeling+with+lavaan-p-9781119578994.html:text/html;Structural Equation Modeling with lavaan  Wiley.pdf:/home/deadhand/Zotero/storage/BU4R9IWE/Structural Equation Modeling with lavaan  Wiley.pdf:application/pdf},
}

@article{lai_problem_2016,
	title = {The {Problem} with {Having} {Two} {Watches}: {Assessment} of {Fit} {When} {RMSEA} and {CFI} {Disagree}},
	issn = {0027-3171},
	shorttitle = {The {Problem} with {Having} {Two} {Watches}},
	url = {http://www.scopus.com/inward/record.url?scp=84961637017&partnerID=8YFLogxK},
	doi = {10.1080/00273171.2015.1134306},
	abstract = {The root mean square error of approximation (RMSEA) and the comparative fit index (CFI) are two widely applied indices to assess fit of structural equation models. Because these two indices are viewed positively by researchers, one might presume that their values would yield comparable qualitative assessments of model fit for any data set. When RMSEA and CFI offer different evaluations of model fit, we argue that researchers are likely to be confused and potentially make incorrect research conclusions. We derive the necessary as well as the sufficient conditions for inconsistent interpretations of these indices. We also study inconsistency in results for RMSEA and CFI at the sample level. Rather than indicating that the model is misspecified in a particular manner or that there are any flaws in the data, the two indices can disagree because (a) they evaluate, by design, the magnitude of the model's fit function value from different perspectives; (b) the cutoff values for these indices are arbitrary; and (c) the meaning of “good” fit and its relationship with fit indices are not well understood. In the context of inconsistent judgments of fit using RMSEA and CFI, we discuss the implications of using cutoff values to evaluate model fit in practice and to design SEM studies.},
	urldate = {2021-11-29},
	journal = {Multivariate Behavioral Research},
	author = {Lai, Keke and Green, Samuel B.},
	month = feb,
	year = {2016},
	keywords = {comparative fit index, fit indices, root mean square error of approximation, Structural equation modeling},
	pages = {1--20},
	file = {The Problem with Having Two Watches\: Assessment of Fit When RMSEA and CFI Disagree:/home/deadhand/Zotero/storage/69MWMU6M/lai2016.pdf.pdf:application/pdf},
}

@article{kim_assessing_2021,
	title = {Assessing {Compassion} in {Korean} {Population}: {Psychometric} {Properties} of the {Korean} {Version} of {Sussex}-{Oxford} {Compassion} {Scales}},
	volume = {12},
	issn = {1664-1078},
	shorttitle = {Assessing {Compassion} in {Korean} {Population}},
	doi = {10.3389/fpsyg.2021.744481},
	abstract = {A newly developed scale, the Sussex-Oxford Compassion Scale (SOCS) measures compassion for others and the self-based on an empirically supported five-elements definition of compassion: (a) recognizing suffering; (b) understanding the universality of suffering; (c) feeling for the person suffering; (d) tolerating uncomfortable feelings; and (e) motivation to act/acting to alleviate suffering. This study aimed to validate a Korean version of SOCS in a Korean adult sample. We administered the Sussex-Oxford Compassion Scale for Others (SOCS-O), the Sussex-Oxford Compassion Scale for the Self (SOCS-S), and other self-report measures of mindfulness, self-compassion, compassionate love, wellbeing, interpersonal reactivity, and mental health problems to analyze their psychometric properties. The findings support the five-factor hierarchical structure for the SOCS-O and SOCS-S, and as well as both scales' adequate psychometric properties of measurement invariance, interpretability, internal consistency, floor/ceiling effects, and convergent/discriminant validity.},
	language = {eng},
	journal = {Frontiers in Psychology},
	author = {Kim, Jiyoung and Seo, Jang-Won},
	year = {2021},
	pmid = {34707546},
	pmcid = {PMC8544640},
	keywords = {validity, compassion, self-compassion, SOCS-O, SOCS-S},
	pages = {744481},
	file = {Full Text:/home/deadhand/Zotero/storage/57YLTMG7/Kim and Seo - 2021 - Assessing Compassion in Korean Population Psychom.pdf:application/pdf},
}

@article{jak_analytical_2021,
	title = {Analytical power calculations for structural equation modeling: {A} tutorial and {Shiny} app},
	volume = {53},
	issn = {1554-3528},
	shorttitle = {Analytical power calculations for structural equation modeling},
	url = {https://doi.org/10.3758/s13428-020-01479-0},
	doi = {10.3758/s13428-020-01479-0},
	abstract = {Conducting a power analysis can be challenging for researchers who plan to analyze their data using structural equation models (SEMs), particularly when Monte Carlo methods are used to obtain power. In this tutorial, we explain how power calculations without Monte Carlo methods for the χ2 test and the RMSEA tests of (not-)close fit can be conducted using the Shiny app “power4SEM”. power4SEM facilitates power calculations for SEM using two methods that are not computationally intensive and that focus on model fit instead of the statistical significance of (functions of) parameters. These are the method proposed by Satorra and Saris (Psychometrika 50(1), 83–90, 1985) for power calculations of the likelihood ratio test, and that described by MacCallum, Browne, and Sugawara (Psychol Methods 1(2) 130–149, 1996) for RMSEA-based power calculations. We illustrate the use of power4SEM with examples of power analyses for path models, factor models, and a latent growth model.},
	language = {en},
	number = {4},
	urldate = {2021-12-03},
	journal = {Behavior Research Methods},
	author = {Jak, Suzanne and Jorgensen, Terrence D. and Verdam, Mathilde G. E. and Oort, Frans J. and Elffers, Louise},
	month = aug,
	year = {2021},
	pages = {1385--1406},
	file = {Analytical power calculations for structural equation modeling\: A tutorial and Shiny app:/home/deadhand/Zotero/storage/UWKG8IW6/10.3758@s13428-020-01479-0.pdf.pdf:application/pdf;Springer Full Text PDF:/home/deadhand/Zotero/storage/ZBJNWEQV/Jak et al. - 2021 - Analytical power calculations for structural equat.pdf:application/pdf},
}

@misc{noauthor_warning_nodate,
	title = {warning: "covariance matrix of latent variables is not positive definite"},
	shorttitle = {warning},
	url = {http://www.talkstats.com/threads/warning-covariance-matrix-of-latent-variables-is-not-positive-definite.69220/},
	abstract = {Hi all,

I ran a 5 factor CFA model, and I got a warning saying that the covariance matrix of my latent variables is not positive definite.  I looked into the literature on this and it sounds like, often times, it's due to high collinearity among the variables.  However, the covariance matrix...},
	language = {en-US},
	urldate = {2021-12-03},
	journal = {Statistics Help @ Talk Stats Forum},
	file = {Snapshot:/home/deadhand/Zotero/storage/HFETAHGM/warning-covariance-matrix-of-latent-variables-is-not-positive-definite.69220.html:text/html},
}

@article{wolf_sample_2013,
	title = {Sample {Size} {Requirements} for {Structural} {Equation} {Models}: {An} {Evaluation} of {Power}, {Bias}, and {Solution} {Propriety}},
	volume = {76},
	issn = {0013-1644},
	shorttitle = {Sample {Size} {Requirements} for {Structural} {Equation} {Models}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4334479/},
	doi = {10.1177/0013164413495237},
	abstract = {Determining sample size requirements for structural equation modeling (SEM) is a challenge often faced by investigators, peer reviewers, and grant writers. Recent years have seen a large increase in SEMs in the behavioral science literature, but consideration of sample size requirements for applied SEMs often relies on outdated rules-of-thumb. This study used Monte Carlo data simulation techniques to evaluate sample size requirements for common applied SEMs. Across a series of simulations, we systematically varied key model properties, including number of indicators and factors, magnitude of factor loadings and path coefficients, and amount of missing data. We investigated how changes in these parameters affected sample size requirements with respect to statistical power, bias in the parameter estimates, and overall solution propriety. Results revealed a range of sample size requirements (i.e., from 30 to 460 cases), meaningful patterns of association between parameters and sample size, and highlight the limitations of commonly cited rules-of-thumb. The broad “lessons learned” for determining SEM sample size requirements are discussed.},
	number = {6},
	urldate = {2021-12-03},
	journal = {Educational and psychological measurement},
	author = {Wolf, Erika J. and Harrington, Kelly M. and Clark, Shaunna L. and Miller, Mark W.},
	month = dec,
	year = {2013},
	pmid = {25705052},
	pmcid = {PMC4334479},
	pages = {913--934},
	file = {PubMed Central Full Text PDF:/home/deadhand/Zotero/storage/KARPF67V/Wolf et al. - 2013 - Sample Size Requirements for Structural Equation M.pdf:application/pdf;Sample Size Requirements for Structural Equation Models\: An Evaluation of Power, Bias, and Solution Propriety:/home/deadhand/Zotero/storage/NUI3NEDZ/wolf2013.pdf.pdf:application/pdf},
}

@article{stark_guide_2019,
	title = {Guide to {Decision}-{Making} in {Exploratory} {Factor} {Analysis}},
	author = {Stark, Roland},
	month = jun,
	year = {2019},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/HK6T3UGW/Stark - 2019 - Guide to Decision-Making in Exploratory Factor Ana.pdf:application/pdf},
}

@article{goretzko_exploratory_2021,
	title = {Exploratory factor analysis: {Current} use, methodological developments and recommendations for good practice},
	volume = {40},
	issn = {1936-4733},
	shorttitle = {Exploratory factor analysis},
	url = {https://doi.org/10.1007/s12144-019-00300-2},
	doi = {10.1007/s12144-019-00300-2},
	abstract = {Psychological research often relies on Exploratory Factor Analysis (EFA). As the outcome of the analysis highly depends on the chosen settings, there is a strong need for guidelines in this context. Therefore, we want to examine the recent methodological developments as well as the current practice in psychological research. We reviewed ten years of studies containing EFAs and contrasted them with new methodological options. We focused on four major issues: an adequate sample size, the extraction method, the rotation method and the factor retention criterion determining the number of factors. Finally, we present modified recommendations based on these reviewed empirical studies and practical considerations.},
	language = {en},
	number = {7},
	urldate = {2021-12-06},
	journal = {Current Psychology},
	author = {Goretzko, David and Pham, Trang Thien Huong and Bühner, Markus},
	month = jul,
	year = {2021},
	pages = {3510--3521},
	file = {Exploratory factor analysis\: Current use, methodological developments and recommendations for good practice:/home/deadhand/Zotero/storage/64CS94X2/goretzko2019.pdf.pdf:application/pdf},
}

@article{merkle_blavaan_2018,
	title = {blavaan: {Bayesian} {Structural} {Equation} {Models} via {Parameter} {Expansion}},
	volume = {85},
	copyright = {Copyright (c) 2018 Edgar C. Merkle, Yves Rosseel},
	issn = {1548-7660},
	shorttitle = {blavaan},
	url = {https://doi.org/10.18637/jss.v085.i04},
	doi = {10.18637/jss.v085.i04},
	abstract = {This article describes blavaan, an R package for estimating Bayesian structural equation models (SEMs) via JAGS and for summarizing the results. It also describes a novel parameter expansion approach for estimating specific types of models with residual covariances, which facilitates estimation of these models in JAGS. The methodology and software are intended to provide users with a general means of estimating Bayesian SEMs, both classical and novel, in a straightforward fashion. Users can estimate Bayesian versions of classical SEMs with lavaan syntax, they can obtain state-of-the-art Bayesian fit measures associated with the models, and they can export JAGS code to modify the SEMs as desired. These features and more are illustrated by example, and the parameter expansion approach is explained in detail.},
	language = {en},
	urldate = {2021-12-15},
	journal = {Journal of Statistical Software},
	author = {Merkle, Edgar C. and Rosseel, Yves},
	month = jun,
	year = {2018},
	keywords = {lavaan},
	pages = {1--30},
	file = {Full Text:/home/deadhand/Zotero/storage/HTL7J95J/Merkle and Rosseel - 2018 - blavaan Bayesian Structural Equation Models via P.pdf:application/pdf},
}

@article{depaoli_parameter_2021,
	title = {Parameter {Specification} in {Bayesian} {CFA}: {An} {Exploration} of {Multivariate} and {Separation} {Strategy} {Priors}},
	volume = {28},
	issn = {1070-5511},
	shorttitle = {Parameter {Specification} in {Bayesian} {CFA}},
	url = {https://doi.org/10.1080/10705511.2021.1894154},
	doi = {10.1080/10705511.2021.1894154},
	abstract = {The impact of parameter and prior specifications on Bayesian SEM estimates is examined through two simulation studies. The model of focus was a CFA. Simulation conditions for Study 1 included varying sample size, the strength of the factor loadings (also tied to issues of reliability), factor correlation strength, and estimation conditions tied to different parameter specifications. Study 2 extended these factors and included non-zero cross-loadings to highlight the flexibility that Bayesian methods afford CFAs. The main goal of these studies was to examine the impact of different parameter specifications, as crossed with different forms of prior distributions, on the accuracy of parameter estimates–examined via relative bias. We examined several parameter specification conditions focused on the latent factor covariance specification, and then crossed these conditions with different prior forms (multivariate and separation strategy priors). Findings highlight where parameter specification implemented had an overall larger impact on the accuracy of results obtained.},
	number = {5},
	urldate = {2021-12-15},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Depaoli, Sarah and Liu, Haiyan and Marvin, Lydia},
	month = sep,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10705511.2021.1894154},
	keywords = {Bayesian estimation, prior distributions, confirmatory factor analysis, parameter specification, priors, structural equation modeling},
	pages = {699--715},
	file = {Parameter Specification in Bayesian CFA\: An Exploration of Multivariate and Separation Strategy Priors:/home/deadhand/Zotero/storage/YHXG6U3U/depaoli2021.pdf.pdf:application/pdf},
}

@misc{noauthor_wambs_nodate,
	title = {{WAMBS} {Blavaan} {Tutorial} (using {Stan})},
	url = {https://www.rensvandeschoot.com/tutorials/wambs-blavaan-tutorial-using-stan/},
	abstract = {WAMBS Blavaan Tutorial (using Stan) By Laurent Smeets and Rens van de Schoot Last modified: 19 October 2019 In this tutorial you follow the steps of the When-to-Worry-and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics – checklist (the WAMBS-checklist). We are continuously improving the tutorials so let me know if you discover...},
	language = {en-US},
	urldate = {2021-12-15},
	journal = {Rens van de Schoot},
	file = {Snapshot:/home/deadhand/Zotero/storage/LPPHWQ5E/wambs-blavaan-tutorial-using-stan.html:text/html},
}

@article{taylor_overview_2019,
	title = {Overview and {Illustration} of {Bayesian} {Confirmatory} {Factor} {Analysis} with {Ordinal} {Indicators}},
	volume = {24},
	issn = {1531-7714},
	url = {https://scholarworks.umass.edu/pare/vol24/iss1/4},
	doi = {https://doi.org/10.7275/vk6g-0075},
	number = {1},
	journal = {Practical Assessment, Research, and Evaluation},
	author = {Taylor, John},
	month = nov,
	year = {2019},
	file = {"Overview and Illustration of Bayesian Confirmatory Factor Analysis wit" by John M. Taylor:/home/deadhand/Zotero/storage/IYHZBX72/4.html:text/html},
}

@article{hoofs_evaluating_2018,
	title = {Evaluating {Model} {Fit} in {Bayesian} {Confirmatory} {Factor} {Analysis} {With} {Large} {Samples}: {Simulation} {Study} {Introducing} the {BRMSEA}},
	volume = {78},
	issn = {0013-1644},
	shorttitle = {Evaluating {Model} {Fit} in {Bayesian} {Confirmatory} {Factor} {Analysis} {With} {Large} {Samples}},
	url = {https://doi.org/10.1177/0013164417709314},
	doi = {10.1177/0013164417709314},
	abstract = {Bayesian confirmatory factor analysis (CFA) offers an alternative to frequentist CFA based on, for example, maximum likelihood estimation for the assessment of reliability and validity of educational and psychological measures. For increasing sample sizes, however, the applicability of current fit statistics evaluating model fit within Bayesian CFA is limited. We propose, therefore, a Bayesian variant of the root mean square error of approximation (RMSEA), the BRMSEA. A simulation study was performed with variations in model misspecification, factor loading magnitude, number of indicators, number of factors, and sample size. This showed that the 90\% posterior probability interval of the BRMSEA is valid for evaluating model fit in large samples (N≥ 1,000), using cutoff values for the lower ({\textless}.05) and upper limit ({\textless}.08) as guideline. An empirical illustration further shows the advantage of the BRMSEA in large sample Bayesian CFA models. In conclusion, it can be stated that the BRMSEA is well suited to evaluate model fit in large sample Bayesian CFA models by taking sample size and model complexity into account.},
	language = {en},
	number = {4},
	urldate = {2021-12-15},
	journal = {Educational and Psychological Measurement},
	author = {Hoofs, Huub and van de Schoot, Rens and Jansen, Nicole W. H. and Kant, IJmert},
	month = aug,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	keywords = {validity, Bayesian procedures, factor analysis, model fit, simulation},
	pages = {537--568},
	file = {Evaluating Model Fit in Bayesian Confirmatory Factor Analysis With Large Samples\: Simulation Study Introducing the BRMSEA:/home/deadhand/Zotero/storage/R58LDQTJ/hoofs2017.pdf.pdf:application/pdf;SAGE PDF Full Text:/home/deadhand/Zotero/storage/6X9KRGME/Hoofs et al. - 2018 - Evaluating Model Fit in Bayesian Confirmatory Fact.pdf:application/pdf},
}

@article{lu_comparison_2017,
	title = {A comparison of {Bayesian} and frequentist model selection methods for factor analysis models},
	volume = {22},
	issn = {1939-1463},
	doi = {10.1037/met0000145},
	abstract = {We compare the performances of well-known frequentist model fit indices (MFIs) and several Bayesian model selection criteria (MCC) as tools for cross-loading selection in factor analysis under low to moderate sample sizes, cross-loading sizes, and possible violations of distributional assumptions. The Bayesian criteria considered include the Bayes factor (BF), Bayesian Information Criterion (BIC), Deviance Information Criterion (DIC), a Bayesian leave-one-out with Pareto smoothed importance sampling (LOO-PSIS), and a Bayesian variable selection method using the spike-and-slab prior (SSP; Lu, Chow, \& Loken, 2016). Simulation results indicate that of the Bayesian measures considered, the BF and the BIC showed the best balance between true positive rates and false positive rates, followed closely by the SSP. The LOO-PSIS and the DIC showed the highest true positive rates among all the measures considered, but with elevated false positive rates. In comparison, likelihood ratio tests (LRTs) are still the preferred frequentist model comparison tool, except for their higher false positive detection rates compared to the BF, BIC and SSP under violations of distributional assumptions. The root mean squared error of approximation (RMSEA) and the Tucker-Lewis index (TLI) at the conventional cut-off of approximate fit impose much more stringent "penalties" on model complexity under conditions with low cross-loading size, low sample size, and high model complexity compared with the LRTs and all other Bayesian MCC. Nevertheless, they provided a reasonable alternative to the LRTs in cases where the models cannot be readily constructed as nested within each other. (PsycINFO Database Record},
	language = {eng},
	number = {2},
	journal = {Psychological Methods},
	author = {Lu, Zhao-Hua and Chow, Sy-Miin and Loken, Eric},
	month = jun,
	year = {2017},
	pmid = {28594228},
	pmcid = {PMC5527973},
	keywords = {Sample Size, Humans, Factor Analysis, Statistical, Models, Statistical, Bayes Theorem, Likelihood Functions, Models, Psychological},
	pages = {361--381},
	file = {A comparison of Bayesian and frequentist model selection methods for factor analysis models:/home/deadhand/Zotero/storage/GCBXGSR8/lu2017.pdf.pdf:application/pdf;Accepted Version:/home/deadhand/Zotero/storage/DKTUNVTM/Lu et al. - 2017 - A comparison of Bayesian and frequentist model sel.pdf:application/pdf},
}

@article{merkle_efficient_2020,
	title = {Efficient {Bayesian} {Structural} {Equation} {Modeling} in {Stan}},
	url = {http://arxiv.org/abs/2008.07733},
	abstract = {Structural equation models comprise a large class of popular statistical models, including factor analysis models, certain mixed models, and extensions thereof. Model estimation is complicated by the fact that we typically have multiple interdependent response variables and multiple latent variables (which may also be called random effects or hidden variables), often leading to slow and inefficient MCMC samples. In this paper, we describe and illustrate a general, efficient approach to Bayesian SEM estimation in Stan, contrasting it with previous implementations in R package blavaan (Merkle \& Rosseel, 2018). After describing the approaches in detail, we conduct a practical comparison under multiple scenarios. The comparisons show that the new approach is clearly better. We also discuss ways that the approach may be extended to other models that are of interest to psychometricians.},
	urldate = {2021-12-15},
	journal = {arXiv:2008.07733 [stat]},
	author = {Merkle, Edgar C. and Fitzsimmons, Ellen and Uanhoro, James and Goodrich, Ben},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.07733},
	keywords = {Statistics - Computation},
	annote = {Comment: 21 pages, 5 figures},
	file = {arXiv Fulltext PDF:/home/deadhand/Zotero/storage/VEA3ZN9Z/Merkle et al. - 2020 - Efficient Bayesian Structural Equation Modeling in.pdf:application/pdf;arXiv.org Snapshot:/home/deadhand/Zotero/storage/D4PXJSNR/2008.html:text/html},
}

@misc{noauthor_adapting_nodate,
	title = {Adapting fit indices for {Bayesian} structural equation modeling: {Comparison} to maximum likelihood - {PubMed}},
	url = {https://pubmed.ncbi.nlm.nih.gov/31180693/},
	urldate = {2021-12-15},
	file = {Adapting fit indices for Bayesian structural equation modeling\: Comparison to maximum likelihood - PubMed:/home/deadhand/Zotero/storage/6SVSAXTA/31180693.html:text/html},
}

@article{graves_note_2021,
	title = {A note on identification constraints and information criteria in {Bayesian} latent variable models},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-021-01649-8},
	doi = {10.3758/s13428-021-01649-8},
	abstract = {It is well known that, in traditional SEM applications, a scale must be set for each latent variable: typically, either the latent variance or a factor loading is fixed to one. While this has no impact on the fit metrics in ML estimation, it can potentially lead to varying Bayesian model comparison metrics due to the use of different prior distributions under each parameterization. This is a problem, because a researcher could artificially improve one’s preferred model simply by changing the identification constraint. Using a single-factor CFA as motivation for study, we first show that Bayesian model comparison metrics can systematically change depending on constraints used. We then study principled methods for setting the scale of the latent variable that stabilize the model comparison metrics. These methods involve (i) the placement of priors on ratios of factor loadings, as opposed to individual loadings; and (ii) use of effect coding. We illustrate the methods via simulation and application.},
	language = {en},
	urldate = {2021-12-17},
	journal = {Behavior Research Methods},
	author = {Graves, Benjamin and Merkle, Edgar C.},
	month = aug,
	year = {2021},
	file = {Springer Full Text PDF:/home/deadhand/Zotero/storage/B84BW8Y7/Graves and Merkle - 2021 - A note on identification constraints and informati.pdf:application/pdf},
}

@article{hayes_use_2020,
	title = {Use {Omega} {Rather} than {Cronbach}’s {Alpha} for {Estimating} {Reliability}. {But}…},
	volume = {14},
	issn = {1931-2458},
	url = {https://doi.org/10.1080/19312458.2020.1718629},
	doi = {10.1080/19312458.2020.1718629},
	abstract = {Cronbach’s alpha (α) is a widely-used measure of reliability used to quantify the amount of random measurement error that exists in a sum score or average generated by a multi-item measurement scale. Yet methodologists have warned that α is not an optimal measure of reliability relative to its more general form, McDonald’s omega (ω). Among other reasons, that the computation of ω is not available as an option in many popular statistics programs and requires items loadings from a confirmatory factor analysis (CFA) have probably hindered more widespread adoption. After a bit of discussion of α versus ω, we illustrate the computation of ω using two structural equation modeling programs (Mplus and AMOS) and the MBESS package for R. We then describe a macro for SPSS and SAS (OMEGA) that calculates ω in two ways without relying on the estimation of loadings or error variances using CFA. We show that it produces estimates of ω that are nearly identical to when using CFA-based estimates of item loadings and error variances. We also discuss the use of the OMEGA macro for certain forms of item analysis and brief form construction based on the removal of items from a longer scale.},
	number = {1},
	urldate = {2022-01-28},
	journal = {Communication Methods and Measures},
	author = {Hayes, Andrew F. and Coutts, Jacob J.},
	month = jan,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19312458.2020.1718629},
	pages = {1--24},
	file = {Use Omega Rather than Cronbach’s Alpha for Estimating Reliability. But…:/home/deadhand/Zotero/storage/RIHHN6BM/10.1080@19312458.2020.1718629.pdf.pdf:application/pdf},
}

@article{goodboy_omega_2020,
	title = {Omega over alpha for reliability estimation of unidimensional communication measures},
	volume = {44},
	issn = {2380-8985},
	url = {https://doi.org/10.1080/23808985.2020.1846135},
	doi = {10.1080/23808985.2020.1846135},
	abstract = {Cronbach’s alpha (coefficient α) is the conventional statistic communication scholars use to estimate the reliability of multi-item measurement instruments. For many, if not most communication measures, α should not be calculated for reliability estimation. Instead, coefficient omega (ω) should be reported as it aligns with the definition of reliability itself. In this primer, we review α and ω, and explain why ω should be the new ‘gold standard’ in reliability estimation. Using Mplus, we demonstrate how ω is calculated on an available data set and show how preliminary scales can be revised with ‘ω if item deleted.’ We also list several easy-to-use resources to calculate ω in other software programs. Communication researchers should routinely report ω instead of α.},
	number = {4},
	urldate = {2022-01-28},
	journal = {Annals of the International Communication Association},
	author = {Goodboy, Alan K. and Martin, Matthew M.},
	month = oct,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/23808985.2020.1846135},
	keywords = {Communication measurement, Cronbach’s alpha, McDonald’s omega, Reliability},
	pages = {422--439},
	file = {Omega over alpha for reliability estimation of unidimensional communication measures:/home/deadhand/Zotero/storage/57LRZ77Y/10.1080@23808985.2020.1846135.pdf.pdf:application/pdf},
}

@article{gagne_measurement_2006,
	title = {Measurement {Model} {Quality}, {Sample} {Size}, and {Solution} {Propriety} in {Confirmatory} {Factor} {Models}},
	volume = {41},
	issn = {0027-3171},
	doi = {10.1207/s15327906mbr4101_5},
	abstract = {Sample size recommendations in confirmatory factor analysis (CFA) have recently shifted away from observations per variable or per parameter toward consideration of model quality. Extending research by Marsh, Hau, Balla, and Grayson (1998), simulations were conducted to determine the extent to which CFA model convergence and parameter estimation are affected by n as well as by construct reliability, which is a measure of measurement model quality derived from the number of indicators per factor (p/f) and factor loading magnitude. Results indicated that model convergence and accuracy of parameter estimation were affected by n and by construct reliability within levels of n. Sample size recommendations for applied researchers using CFA are presented herein as a function of relevant design characteristics.},
	language = {eng},
	number = {1},
	journal = {Multivariate Behavioral Research},
	author = {Gagne, Phill and Hancock, Gregory R.},
	month = mar,
	year = {2006},
	pmid = {26788895},
	pages = {65--83},
	file = {Measurement Model Quality, Sample Size, and Solution Propriety in Confirmatory Factor Models:/home/deadhand/Zotero/storage/X5IGWATJ/gagne2006.pdf.pdf:application/pdf},
}

@misc{noauthor_psych_nodate,
	title = {psych citation info},
	url = {https://cran.r-project.org/web/packages/psych/citation.html},
	urldate = {2022-02-05},
	file = {psych citation info:/home/deadhand/Zotero/storage/YIW4ZI5D/citation.html:text/html},
}

@article{burkner_ordinal_2019,
	title = {Ordinal {Regression} {Models} in {Psychology}: {A} {Tutorial}},
	volume = {2},
	issn = {2515-2459},
	shorttitle = {Ordinal {Regression} {Models} in {Psychology}},
	url = {https://doi.org/10.1177/2515245918823199},
	doi = {10.1177/2515245918823199},
	abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
	language = {en},
	number = {1},
	urldate = {2022-03-26},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Bürkner, Paul-Christian and Vuorre, Matti},
	month = mar,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {brms, Likert items, open data, open materials, ordinal models, R},
	pages = {77--101},
	file = {SAGE PDF Full Text:/home/deadhand/Zotero/storage/5LF8JZTS/Bürkner and Vuorre - 2019 - Ordinal Regression Models in Psychology A Tutoria.pdf:application/pdf},
}

@article{asparouhov_advances_2021,
	title = {Advances in {Bayesian} {Model} {Fit} {Evaluation} for {Structural} {Equation} {Models}},
	volume = {28},
	issn = {1070-5511},
	url = {https://doi.org/10.1080/10705511.2020.1764360},
	doi = {10.1080/10705511.2020.1764360},
	abstract = {In this article, we discuss the Posterior Predictive P-value (PPP) method in the presence of missing data, the Bayesian adaptation of the approximate fit indices RMSEA, CFI and TLI, as well as the Bayesian adaptation of the Wald test for nested models. Simulation studies are presented. We also illustrate how these new methods can be used to build BSEM models.},
	number = {1},
	urldate = {2022-03-26},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Asparouhov, Tihomir and Muthén, Bengt},
	month = jan,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10705511.2020.1764360},
	keywords = {Bayesian fit indices, Bayesian Wald test, BSEM, PPP with missing data},
	pages = {1--14},
	file = {Snapshot:/home/deadhand/Zotero/storage/5DSUT9YU/10705511.2020.html:text/html},
}

@article{liang_performance_2020,
	title = {The {Performance} of {ESEM} and {BSEM} in {Structural} {Equation} {Models} with {Ordinal} {Indicators}},
	volume = {27},
	issn = {1070-5511},
	url = {https://doi.org/10.1080/10705511.2020.1716770},
	doi = {10.1080/10705511.2020.1716770},
	abstract = {Recent developments allow for incorporating exploratory features into structural equation models (SEM). Two approaches, exploratory SEM (ESEM) and Bayesian SEM (BSEM), have been shown flexible of estimating complex SEM. This simulation study compared the performance of ESEM and BSEM for estimating structural regression models with ordinal indicators where cross-loadings were present in selected factors. Data were generated under conditions including various categorical data distributions, similarity of categorical distributions across indicators, and sample sizes. ESEM with Geomin rotation and BSEM with four small-variance normal priors on cross-loadings were used. Results indicated that ESEM may be prioritized over BSEM when sample sizes were large, distributions of ordinal indicators were symmetric or moderately asymmetric, and cross-loadings were non-ignorable. When sample sizes were relatively small, we recommend using one approach to complement the other. For BSEM, a sensitivity test is recommended to evaluate the impact of various prior choices on the estimation outcomes.},
	number = {6},
	urldate = {2022-03-26},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Liang, Xinya and Yang, Yanyun and Cao, Chunhua},
	month = nov,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10705511.2020.1716770},
	keywords = {exploratory structural equation modeling, Bayesian structural equation modeling, informative priors, Ordinal data},
	pages = {874--887},
	file = {Snapshot:/home/deadhand/Zotero/storage/VUPKIFZG/10705511.2020.html:text/html},
}

@misc{noauthor_sci-hub_nodate,
	title = {Sci-{Hub} {\textbar} {The} {Performance} of {ESEM} and {BSEM} in {Structural} {Equation} {Models} with {Ordinal} {Indicators}. {Structural} {Equation} {Modeling}: {A} {Multidisciplinary} {Journal}, 1–14 {\textbar} 10.1080/10705511.2020.1716770},
	url = {https://sci-hub.ru/10.1080/10705511.2020.1716770},
	urldate = {2022-03-26},
	file = {Sci-Hub | The Performance of ESEM and BSEM in Structural Equation Models with Ordinal Indicators. Structural Equation Modeling\: A Multidisciplinary Journal, 1–14 | 10.1080/10705511.2020.1716770:/home/deadhand/Zotero/storage/RVFGDHPF/10705511.2020.html:text/html},
}

@article{wei_evaluation_2022,
	title = {Evaluation and {Comparison} of {SEM}, {ESEM}, and {BSEM} in {Estimating} {Structural} {Models} with {Potentially} {Unknown} {Cross}-loadings},
	volume = {0},
	issn = {1070-5511},
	url = {https://doi.org/10.1080/10705511.2021.2006664},
	doi = {10.1080/10705511.2021.2006664},
	abstract = {Cross-loadings are common in multidimensional instruments; however, they cannot be appropriately addressed in conventional structural equation modeling (SEM) owing to the assumption of zero cross-loadings in standard confirmatory factor analysis (CFA). Although it has been proposed that exploratory structural equation modeling (ESEM) and Bayesian structural equation modeling (BSEM) can address this issue more flexibly, their performance in structural parameter estimation has not been adequately compared. This study uses simulated data to evaluate and compare SEM, ESEM, and BSEM in estimating structural models under different manipulation conditions (i.e., sample size, target loading, cross-loading, and path coefficient). The results demonstrated that the performances of these approaches were similar in the case of zero cross-loadings. SEM performed worse as cross-loadings increased, and the performance of BSEM significantly depended on the accuracy of the priors for cross-loadings. ESEM was inferior to BSEM with correctly specified prior means for cross-loadings in most evaluation measures and exhibits unstable performance in conditions with small target loadings. Recommended strategies for selecting an appropriate modeling approach are discussed based on our findings.},
	number = {0},
	urldate = {2022-03-26},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Wei, Xiayan and Huang, Jiasheng and Zhang, Lijin and Pan, Deng and Pan, Junhao},
	month = feb,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10705511.2021.2006664},
	keywords = {BSEM, cross-loadings, ESEM, structural parameter estimation},
	pages = {1--12},
	file = {Snapshot:/home/deadhand/Zotero/storage/7AUAULYA/10705511.2021.html:text/html},
}

@article{gilbert_development_2017-1,
	title = {The development of compassionate engagement and action scales for self and others},
	volume = {4},
	doi = {10.1186/s40639-017-0033-3},
	abstract = {Background
Studies of the value of compassion on physical and mental health and social relationships have proliferated in the last 25 years. Although, there are several conceptualisations and measures of compassion, this study develops three new measures of compassion competencies derived from an evolutionary, motivational approach. The scales assess 1. the compassion we experience for others, 2. the compassion we experience from others, and 3. self-compassion based on a standard definition of compassion as a ‘sensitivity to suffering in self and others with a commitment to try to alleviate and prevent it’. We explored these in relationship to other compassion scales, self-criticism, depression, anxiety, stress and well-being. Methods
Participants from three different countries (UK, Portugal and USA) completed a range of scales including compassion for others, self-compassion, self-criticism, shame, depression, anxiety and stress with the newly developed ‘The Compassionate Engagement and Actions’ scale. ResultsAll three scales have good validity. Interestingly, we found that the three orientations of compassion are only moderately correlated to one another (r {\textless} .5). We also found that some elements of self-compassion (e.g., being sensitive to, and moved by one’s suffering) have a complex relationship with other attributes of compassion (e.g., empathy), and with depression, anxiety and stress.A path-analysis showed that self-compassion is a significant mediator of the association between self-reassurance and well-being, while self-criticism has a direct effect on depressive symptoms, not mediated by self-compassion. DiscussionCompassion evolved from caring motivation and in humans is associated with a range of different socially intelligent competencies. Understanding how these competencies can be inhibited and facilitated is an important research endeavour. These new scales were designed to assess these competencies. Conclusions
This is the first study to measure the three orientations of compassion derived from an evolutionary model of caring motivation with specified competencies. Our three new measures of compassion further indicate important complex relationships between different potentiation’s of compassion, well-being, and vulnerability to psychopathologies.},
	journal = {Journal of Compassionate Health Care},
	author = {Gilbert, Paul and Catarino, Francisca and Duarte, Cristiana and Matos, Marcela and Kolts, Russell and Stubbs, James and Ceresatto, Laura and Duarte, Joana and Pinto-Gouveia, José and Basran, Jaskaran},
	month = dec,
	year = {2017},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/HSRNSI52/Gilbert et al. - 2017 - The development of compassionate engagement and ac.pdf:application/pdf},
}

@article{cooperman_heywood_2022,
	title = {Heywood you go away! {Examining} causes, effects, and treatments for {Heywood} cases in exploratory factor analysis},
	volume = {27},
	issn = {1939-1463},
	doi = {10.1037/met0000384},
	abstract = {Exploratory factor analysis (EFA) is a popular method for elucidating the latent structure of data. Unfortunately, EFA models can sometimes produce improper solutions with nonsensical results. For example, improper EFA solutions can include one or more Heywood cases, where common factors account for 100\% or more of an observed variable's variance. To better understand these senseless estimates, we conducted four Monte Carlo studies that illuminate the (a) causes, (b) consequences, and (c) effective treatments for Heywood cases in EFA models. Studies 1 and 2 showed that numerous model and data characteristics are associated with Heywood cases, such as small sample sizes, poorly defined factors with low factor score determinacy values, and factor overextraction. In Study 3, we examined the consequences of Heywood cases for EFA model interpretation and found that Heywood cases increase factor loading variances and upwardly bias factor score determinacy values. Study 4 compared the model recovery of several EFA algorithms that were designed to avoid Heywood cases. Our results indicated that, among the algorithms compared, regularized common factor analysis (Jung \& Takane, 2008) was the most reliable method for avoiding Heywood cases and producing EFA parameter estimates with small mean squared errors. We discuss best practices for conducting EFA with data sets that might yield Heywood cases. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
	language = {eng},
	number = {2},
	journal = {Psychological Methods},
	author = {Cooperman, Allison W. and Waller, Niels G.},
	month = apr,
	year = {2022},
	pmid = {34197140},
	keywords = {Sample Size, Humans, Factor Analysis, Statistical, Bias, Causality, Monte Carlo Method},
	pages = {156--176},
}

@misc{wang_heywood_2021,
	title = {Heywood cases in unidimensional factor models and item response models for binary data},
	url = {http://arxiv.org/abs/2108.04925},
	doi = {10.48550/arXiv.2108.04925},
	abstract = {Heywood cases are known from linear factor analysis literature as variables with communalities larger than 1.00, and in present day factor models, the problem also shows in negative residual variances. For binary data, ordinal factor models can be applied with either delta parameterization or theta parametrization. The former is more common than the latter and can yield Heywood cases when limited information estimation is used. The same problem shows up as nonconvergence cases in theta parameterized factor models and as extremely large discriminations in item response theory (IRT) models. In this study, we explain why the same problem appears in different forms depending on the method of analysis. We first discuss this issue using equations and then illustrate our conclusions using a small simulation study, where all three methods, delta and theta parameterized ordinal factor models (with estimation based on polychoric correlations) and an IRT model (with full information estimation), are used to analyze the same datasets. We also compared the performances of the WLS, WLSMV, and ULS estimators for the ordinal factor models. Finally, we analyze real data with the same three approaches. The results of the simulation study and the analysis of real data confirm the theoretical conclusions.},
	urldate = {2022-08-16},
	publisher = {arXiv},
	author = {Wang, Selena and De Boeck, Paul and Yotebieng, Marcel},
	month = aug,
	year = {2021},
	note = {arXiv:2108.04925 [stat]},
	keywords = {Statistics - Methodology, Statistics - Applications},
	file = {arXiv Fulltext PDF:/home/deadhand/Zotero/storage/CNFYG4AN/Wang et al. - 2021 - Heywood cases in unidimensional factor models and .pdf:application/pdf;arXiv.org Snapshot:/home/deadhand/Zotero/storage/VRXNNL55/2108.html:text/html},
}

@article{cooperman_heywood_2022-1,
	title = {Heywood you go away! {Examining} causes, effects, and treatments for {Heywood} cases in exploratory factor analysis},
	volume = {27},
	issn = {1939-1463},
	doi = {10.1037/met0000384},
	abstract = {Exploratory factor analysis (EFA) is a popular method for elucidating the latent structure of data. Unfortunately, EFA models can sometimes produce improper solutions with nonsensical results. For example, improper EFA solutions can include one or more Heywood cases, where common factors account for 100\% or more of an observed variable’s variance. To better understand these senseless estimates, we conducted four Monte Carlo studies that illuminate the (a) causes, (b) consequences, and (c) effective treatments for Heywood cases in EFA models. Studies 1 and 2 showed that numerous model and data characteristics are associated with Heywood cases, such as small sample sizes, poorly defined factors with low factor score determinacy values, and factor overextraction. In Study 3, we examined the consequences of Heywood cases for EFA model interpretation and found that Heywood cases increase factor loading variances and upwardly bias factor score determinacy values. Study 4 compared the model recovery of several EFA algorithms that were designed to avoid Heywood cases. Our results indicated that, among the algorithms compared, regularized common factor analysis (Jung \& Takane, 2008) was the most reliable method for avoiding Heywood cases and producing EFA parameter estimates with small mean squared errors. We discuss best practices for conducting EFA with data sets that might yield Heywood cases. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Methods},
	author = {Cooperman, Allison W. and Waller, Niels G.},
	year = {2022},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Sample Size, Simulation, Models, Algorithms, Exploratory Factor Analysis, Common Factors, Error Analysis},
	pages = {156--176},
	file = {Snapshot:/home/deadhand/Zotero/storage/XVHS2N2X/2021-59793-001.html:text/html},
}

@article{halamova_psychometric_2020,
	title = {{PSYCHOMETRIC} {ANALYSIS} {OF} {THE} {SLOVAK} {VERSION} {OF} {THE} {COMPASSIONATE} {ENGAGEMENT} {AND} {ACTION} {SCALES}},
	volume = {28},
	number = {1},
	journal = {Journal of Psychological and Educational Research},
	author = {Halamová, Júlia and Kanovskỳ, Martin and Pacúchová, Monika},
	year = {2020},
	note = {Publisher: University of Oradea, Faculty of Social and Humanistic Sciences},
	pages = {64--80},
}

@article{lee_problems_2013,
	title = {Problems with {Formative} and {Higher}-{Order} {Reflective} {Variables}},
	volume = {66},
	doi = {10.1016/j.jbusres.2012.08.004},
	abstract = {Cadogan and Lee (this issue) discuss the problems inherent in modeling formative latent variables as endogenous. In response to the commentaries by Rigdon (this issue) and Finn and Wang (this issue), the present article extends the discussion on formative measures. First, the article shows that regardless of whether statistical identification is achieved, researchers are unable to illuminate the nature of a formative latent variable. Second, the study clarifies issues regarding formative indicator weighting, highlighting that the weightings of formative components should be specified as part of the construct definition. Finally, the study shows that higher-order reflective constructs are invalid, highlights the damage their use can inflict on theory development and knowledge accumulation, and provides recommendations on a number of alternative models which should be used in their place (including the formative model).},
	journal = {Journal of Business Research},
	author = {Lee, Nick and Cadogan, John},
	month = feb,
	year = {2013},
	pages = {242--247},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/PRL9ZB5J/Lee and Cadogan - 2013 - Problems with Formative and Higher-Order Reflectiv.pdf:application/pdf},
}

@article{de_krijger_further_2022,
	title = {Further {Validation} of a {Dutch} {Translation} of the {Sussex} {Oxford} {Compassion} for the {Self} {Scale} in {Samples} of {Crisis} {Line} {Volunteers}, {Military} {Personnel} and {Nursing} {Students}},
	volume = {13},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2022.895850},
	abstract = {Self-compassion is considered an important, transdiagnostic factor for mental health. The Sussex Oxford Compassion for the Self Scale (SOCS-S) is a recently developed comprehensive measure of self-compassion, that was found to have promising psychometric properties among health care staff and university students in the initial validation study. The aim of this study is the further psychometric evaluation of a Dutch translation of the SOCS-S in different populations and settings. The SOCS-S was administered in three different Dutch samples [crisis line volunteers (n = 560), military personnel (n = 244) and nursing students (n = 255)]. The results confirm the five-factor structure of the SOCS-S and its reliability and criterion and convergent validity across the samples. Measurement invariance was demonstrated for gender in two samples and for age in all three samples, but not across professions. Finally, the SOCS-S was found to explain additional variance in mental health in comparison to a widely used self-compassion measure (SCS-SF).},
	urldate = {2022-08-21},
	journal = {Frontiers in Psychology},
	author = {de Krijger, Eva and Willems, Renate and ten Klooster, Peter and Bakker, Ellen and Miedema, Harald and Drossaert, Constance and Bohlmeijer, Ernst},
	year = {2022},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/YAH6N95A/de Krijger et al. - 2022 - Further Validation of a Dutch Translation of the S.pdf:application/pdf},
}

@misc{noauthor_tabular_nodate,
	title = {Tabular {Lavaan} output .scaled {\textbar} .robust},
	url = {https://groups.google.com/g/lavaan/c/rGitXu9h9zY},
	urldate = {2022-08-24},
	file = {Tabular Lavaan output .scaled | .robust:/home/deadhand/Zotero/storage/MYQKP6JC/rGitXu9h9zY.html:text/html},
}

@inproceedings{guerra_toward_2016,
	title = {Toward a common procedure using likert and likert-type scales in small groups comparative design observations},
	abstract = {Often, users’ opinions in small groups comparative observations are measured through Likert and Likert-type items-based questionnaires. Resulting data are analyzed in order to find any statistical difference whether positive or negative among the two conditions. Due to the confusion around Likert scales ordinal or interval nature, how to statistically analyze them, is still an open matter of discussion. Should it be a parametric or non-parametric approach? This article analyze the existing literature and propose an approach which aim is to avoid fragmentation in this type of researc},
	author = {Guerra, Andrea and Gidel, Thierry and Vezzetti, Enrico},
	month = may,
	year = {2016},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/FCNXAAD2/Guerra et al. - 2016 - Toward a common procedure using likert and likert-.pdf:application/pdf},
}

@article{hu_cutoff_1999,
	title = {Cutoff criteria for fit indexes in covariance structure analysis: {Conventional} criteria versus new alternatives},
	volume = {6},
	shorttitle = {Cutoff criteria for fit indexes in covariance structure analysis},
	number = {1},
	journal = {Structural equation modeling: a multidisciplinary journal},
	author = {Hu, Li-tze and Bentler, Peter M.},
	year = {1999},
	note = {Publisher: Taylor \& Francis},
	pages = {1--55},
	file = {Full Text:/home/deadhand/Zotero/storage/NEMJ5EFM/Hu and Bentler - 1999 - Cutoff criteria for fit indexes in covariance stru.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/YZLR5ERA/10705519909540118.html:text/html},
}

@book{kline_principles_2015,
	title = {Principles and {Practice} of {Structural} {Equation} {Modeling}, {Fourth} {Edition}},
	isbn = {978-1-4625-2335-1},
	abstract = {Emphasizing concepts and rationale over mathematical minutiae, this is the most widely used, complete, and accessible structural equation modeling (SEM) text. Continuing the tradition of using real data examples from a variety of disciplines, the significantly revised fourth edition incorporates recent developments such as Pearl\&\#39;s graphing theory and the structural causal model (SCM), measurement invariance, and more. Readers gain a comprehensive understanding of all phases of SEM, from data collection and screening to the interpretation and reporting of the results. Learning is enhanced by exercises with answers, rules to remember, and topic boxes. The companion website supplies data, syntax, and output for the book\&\#39;s examples--now including files for Amos, EQS, LISREL, Mplus, Stata, and R (lavaan). New to This Edition *Extensively revised to cover important new topics: Pearl\&\#39;s graphing theory and the SCM, causal inference frameworks, conditional process modeling, path models for longitudinal data, item response theory, and more. *Chapters on best practices in all stages of SEM, measurement invariance in confirmatory factor analysis, and significance testing issues and bootstrapping. *Expanded coverage of psychometrics. *Additional computer tools: online files for all detailed examples, previously provided in EQS, LISREL, and Mplus, are now also given in Amos, Stata, and R (lavaan). *Reorganized to cover the specification, identification, and analysis of observed variable models separately from latent variable models. Pedagogical Features *Exercises with answers, plus end-of-chapter annotated lists of further reading. *Real examples of troublesome data, demonstrating how to handle typical problems in analyses. *Topic boxes on specialized issues, such as causes of nonpositive definite correlations. *Boxed rules to remember. *Website promoting a learn-by-doing approach, including syntax and data files for six widely used SEM computer tools.},
	language = {en},
	publisher = {Guilford Publications},
	author = {Kline, Rex B.},
	month = nov,
	year = {2015},
	note = {Google-Books-ID: Q61ECgAAQBAJ},
	keywords = {Social Science / Research, Business \& Economics / Statistics, Education / Statistics, Medical / Psychiatry / General, Psychology / Statistics},
	file = {(Methodology in the Social Sciences) Rex B. Kline - Principles and Practice of Structural Equation Modeling-Guilford Press (2015).pdf:/home/deadhand/Downloads/(Methodology in the Social Sciences) Rex B. Kline - Principles and Practice of Structural Equation Modeling-Guilford Press (2015).pdf:application/pdf},
}

@incollection{bandalos_factor_2018,
	edition = {2},
	title = {Factor {Analysis}: {Exploratory} and {Confirmatory}},
	isbn = {978-1-315-75564-9},
	shorttitle = {Factor {Analysis}},
	abstract = {Factor analysis is a method of modeling the covariation among a set of observed variables as a function of one or more latent constructs. Here, we use the term construct to refer to an unobservable but theoretically defensible entity, such as intelligence, self-efficacy, or creativity. Such constructs are typically considered to be latent in the sense that they are not directly observable (see Bollen, 2002, for a more detailed discussion of latent constructs). The purpose of factor analysis is to assist researchers in identifying and/or understanding the nature of the latent constructs underlying the variables of interest. Technically, these descriptions exclude component analysis, which is a method for reducing the dimensionality of a set of observed variables through the creation of an optimum number of weighted composites. A major difference between factor and component analysis is that in the latter all of the variance is analyzed, whereas in factor analysis, only the shared (common) variance is analyzed. For this reason, factor analysis is sometimes referred to as common factor analysis. In many ways, however, component analysis is very similar to common factor analysis, and many of the desiderata for exploratory factor analysis presented here apply equally to component analysis. Given that the goal of component analysis is to explain as much observed variance as possible via the weighted composites and not, as in common factor analysis, to model the relations among variables as functions of underlying latent variables, those desiderata relating to the importance of theory for factor analysis do not necessarily apply to component analysis (see Widaman, 2007, for a detailed explanation of the conceptual and mathematical distinction between exploratory factor analysis and principal components analysis). This is because, although components may represent constructs, component analysis can still have utility as a data reduction method even if the components themselves are not interpreted. In such cases, the components do not provide an explanation for the variables’ shared variance, but are instead used to represent that shared variance in the most parsimonious manner possible.},
	booktitle = {The {Reviewer}’s {Guide} to {Quantitative} {Methods} in the {Social} {Sciences}},
	publisher = {Routledge},
	author = {Bandalos, Deborah L. and Finney, Sara J.},
	year = {2018},
	note = {Num Pages: 25},
}

@article{streiner_starting_2003,
	title = {Starting at the {Beginning}: {An} {Introduction} to {Coefficient} {Alpha} and {Internal} {Consistency}},
	volume = {80},
	issn = {0022-3891},
	shorttitle = {Starting at the {Beginning}},
	url = {https://doi.org/10.1207/S15327752JPA8001_18},
	doi = {10.1207/S15327752JPA8001_18},
	abstract = {Cronbach's α is the most widely used index of the reliability of a scale. However, its use and interpretation can be subject to a number of errors. This article discusses the historical development of a from other indexes of internal consistency (split-half reliability and Kuder-Richardson 20) and discusses four myths associated with a: (a) that it is a fixed property of the scale, (b) that it measures only the internal consistency of the scale, (c) that higher values are always preferred over lower ones, and (d) that it is restricted to the range of 0 to 1. It provides some recommendations for acceptable values of a in different situations.},
	number = {1},
	urldate = {2022-09-03},
	journal = {Journal of Personality Assessment},
	author = {Streiner, David L.},
	month = feb,
	year = {2003},
	pmid = {12584072},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/S15327752JPA8001\_18},
	pages = {99--103},
	file = {Starting at the Beginning\: An Introduction to Coefficient Alpha and Internal Consistency:/home/deadhand/Zotero/storage/VWP4PFC5/streiner2003.pdf.pdf:application/pdf},
}

@article{mcneish_thanks_2018,
	title = {Thanks coefficient alpha, we’ll take it from here},
	volume = {23},
	issn = {1939-1463},
	doi = {10.1037/met0000144},
	abstract = {Empirical studies in psychology commonly report Cronbach’s alpha as a measure of internal consistency reliability despite the fact that many methodological studies have shown that Cronbach’s alpha is riddled with problems stemming from unrealistic assumptions. In many circumstances, violating these assumptions yields estimates of reliability that are too small, making measures look less reliable than they actually are. Although methodological critiques of Cronbach’s alpha are being cited with increasing frequency in empirical studies, in this tutorial we discuss how the trend is not necessarily improving methodology used in the literature. That is, many studies continue to use Cronbach’s alpha without regard for its assumptions or merely cite methodological articles advising against its use to rationalize unfavorable Cronbach’s alpha estimates. This tutorial first provides evidence that recommendations against Cronbach’s alpha have not appreciably changed how empirical studies report reliability. Then, we summarize the drawbacks of Cronbach’s alpha conceptually without relying on mathematical or simulation-based arguments so that these arguments are accessible to a broad audience. We continue by discussing several alternative measures that make less rigid assumptions which provide justifiably higher estimates of reliability compared to Cronbach’s alpha. We conclude with empirical examples to illustrate advantages of alternative measures of reliability including omega total, Revelle’s omega total, the greatest lower bound, and Coefficient H. A detailed software appendix is also provided to help researchers implement alternative methods. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Methods},
	author = {McNeish, Daniel},
	year = {2018},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistics, Psychometrics, Empirical Methods, Internal Consistency, Methodology, Test Reliability, Trends},
	pages = {412--433},
	file = {McNeish - 2018 - Thanks coefficient alpha, we’ll take it from here.pdf:/home/deadhand/Zotero/storage/GX9VHP6M/McNeish - 2018 - Thanks coefficient alpha, we’ll take it from here.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/UWSYXZ9I/doiLanding.html:text/html},
}

@article{lai_composite_2021,
	title = {Composite reliability of multilevel data: {It}’s about observed scores and construct meanings},
	volume = {26},
	issn = {1939-1463},
	shorttitle = {Composite reliability of multilevel data},
	doi = {10.1037/met0000287},
	abstract = {This article shows how the concept of reliability of composite scores, as defined in classical test theory, can be extended to the context of multilevel modeling. In particular, it discusses the contributions and limitations of the various level-specific reliability indices proposed by Geldhof, Preacher, and Zyphur (2014), denoted as ω̃b and ω̃w (and also α̃b and α̃w). One major limitation of those indices is that they are quantities for latent, unobserved level-specific composite scores, and are not suitable for observed composites at different levels. As illustrated using simulated data in this article, ω̃b can drastically overestimate the true reliability of between-level composite scores (i.e., observed cluster means). Another limitation is that the development of those indices did not consider the recent conceptual development on construct meanings in multilevel modeling (Stapleton \& Johnson, 2019; Stapleton, Yang, \& Hancock, 2016). To address the second limitation, this article defines reliability indices (ω2l, ωb, ωw, α2l, αb, αw) for three types of multilevel observed composite scores measuring various multilevel constructs: individual, configural, shared, and within-cluster. The article also shows how researchers can obtain sample point and interval estimates using the derived formulas and the provided R and Mplus code. In addition, a large-scale national data set was used to illustrate the proposed methods for estimating reliability for the three types of multilevel composite scores, and practical recommendations on when different indices should be reported are provided. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Methods},
	author = {Lai, Mark H. C.},
	year = {2021},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Simulation, Classical Test Theory, Statistical Reliability},
	pages = {90--102},
	file = {Lai - 2021 - Composite reliability of multilevel data It’s abo.pdf:/home/deadhand/Zotero/storage/34EAX846/Lai - 2021 - Composite reliability of multilevel data It’s abo.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/LL4T4WCI/doiLanding.html:text/html},
}

@article{neff_examining_2019-1,
	title = {Examining the factor structure of the {Self}-{Compassion} {Scale} in 20 diverse samples: {Support} for use of a total score and six subscale scores},
	volume = {31},
	issn = {1939-134X},
	shorttitle = {Examining the factor structure of the {Self}-{Compassion} {Scale} in 20 diverse samples},
	doi = {10.1037/pas0000629},
	abstract = {This study examined the factor structure of the Self-Compassion Scale (SCS) using secondary data drawn from 20 samples (N = 11,685)-7 English and 13 non-English-including 10 community, 6 student, 1 mixed community/student, 1 meditator, and 2 clinical samples. Self-compassion is theorized to represent a system with 6 constituent components: self-kindness, common humanity, mindfulness and reduced self-judgment, isolation and overidentification. There has been controversy as to whether a total score on the SCS or if separate scores representing compassionate versus uncompassionate self-responding should be used. The current study examined the factor structure of the SCS using confirmatory factor analyses (CFA) and Exploratory Structural Equation Modeling (ESEM) to examine 5 distinct models: 1-factor, 2-factor correlated, 6-factor correlated, single-bifactor (1 general self-compassion factor and 6 group factors), and 2-bifactor models (2 correlated general factors each with 3 group factors representing compassionate or uncompassionate self-responding). Results indicated that a 1- and 2-factor solution to the SCS had inadequate fit in every sample examined using both CFA and ESEM, whereas fit was excellent using ESEM for the 6-factor correlated, single-bifactor and correlated 2-bifactor models. However, factor loadings for the correlated 2-bifactor models indicated that 2 separate factors were not well specified. A general factor explained 95\% of the reliable item variance in the single-bifactor model. Results support use of the SCS to examine 6 subscale scores (representing the constituent components of self-compassion) or a total score (representing overall self-compassion), but not separate scores representing compassionate and uncompassionate self-responding. (PsycINFO Database Record (c) 2018 APA, all rights reserved).},
	language = {eng},
	number = {1},
	journal = {Psychological Assessment},
	author = {Neff, Kristin D. and Tóth-Király, István and Yarnell, Lisa M. and Arimitsu, Kohki and Castilho, Paula and Ghorbani, Nima and Guo, Hailan Xiaoxia and Hirsch, Jameson K. and Hupfeld, Jörg and Hutz, Claudio S. and Kotsou, Ilios and Lee, Woo Kyeong and Montero-Marin, Jesus and Sirois, Fuschia M. and de Souza, Luciana K. and Svendsen, Julie L. and Wilkinson, Ross B. and Mantzios, Michail},
	month = jan,
	year = {2019},
	pmid = {30124303},
	keywords = {Humans, Female, Male, Adult, Empathy, Factor Analysis, Statistical, Middle Aged, Psychometrics, Adolescent, Aged, Aged, 80 and over, Self Concept, Young Adult},
	pages = {27--45},
	file = {Neff et al_2019_Examining the factor structure of the Self-Compassion Scale in 20 diverse.pdf:/home/deadhand/Zotero/storage/GDQNYCRJ/Neff et al_2019_Examining the factor structure of the Self-Compassion Scale in 20 diverse.pdf:application/pdf},
}

@article{tennant_warwick-edinburgh_2007,
	title = {The {Warwick}-{Edinburgh} {Mental} {Well}-being {Scale} ({WEMWBS}): development and {UK} validation},
	volume = {5},
	copyright = {2007 Tennant et al; licensee BioMed Central Ltd.},
	issn = {1477-7525},
	shorttitle = {The {Warwick}-{Edinburgh} {Mental} {Well}-being {Scale} ({WEMWBS})},
	url = {https://hqlo.biomedcentral.com/articles/10.1186/1477-7525-5-63},
	doi = {10.1186/1477-7525-5-63},
	abstract = {There is increasing international interest in the concept of mental well-being and its contribution to all aspects of human life. Demand for instruments to monitor mental well-being at a population level and evaluate mental health promotion initiatives is growing. This article describes the development and validation of a new scale, comprised only of positively worded items relating to different aspects of positive mental health: the Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). WEMWBS was developed by an expert panel drawing on current academic literature, qualitative research with focus groups, and psychometric testing of an existing scale. It was validated on a student and representative population sample. Content validity was assessed by reviewing the frequency of complete responses and the distribution of responses to each item. Confirmatory factor analysis was used to test the hypothesis that the scale measured a single construct. Internal consistency was assessed using Cronbach's alpha. Criterion validity was explored in terms of correlations between WEMWBS and other scales and by testing whether the scale discriminated between population groups in line with pre-specified hypotheses. Test-retest reliability was assessed at one week using intra-class correlation coefficients. Susceptibility to bias was measured using the Balanced Inventory of Desired Responding. WEMWBS showed good content validity. Confirmatory factor analysis supported the single factor hypothesis. A Cronbach's alpha score of 0.89 (student sample) and 0.91 (population sample) suggests some item redundancy in the scale. WEMWBS showed high correlations with other mental health and well-being scales and lower correlations with scales measuring overall health. Its distribution was near normal and the scale did not show ceiling effects in a population sample. It discriminated between population groups in a way that is largely consistent with the results of other population surveys. Test-retest reliability at one week was high (0.83). Social desirability bias was lower or similar to that of other comparable scales. WEMWBS is a measure of mental well-being focusing entirely on positive aspects of mental health. As a short and psychometrically robust scale, with no ceiling effects in a population sample, it offers promise as a tool for monitoring mental well-being at a population level. Whilst WEMWBS should appeal to those evaluating mental health promotion initiatives, it is important that the scale's sensitivity to change is established before it is recommended in this context.},
	language = {en},
	number = {1},
	urldate = {2022-09-19},
	journal = {Health and Quality of Life Outcomes},
	author = {Tennant, Ruth and Hiller, Louise and Fishwick, Ruth and Platt, Stephen and Joseph, Stephen and Weich, Scott and Parkinson, Jane and Secker, Jenny and Stewart-Brown, Sarah},
	month = dec,
	year = {2007},
	note = {Number: 1
Publisher: BioMed Central},
	pages = {1--13},
	file = {Full Text PDF:/home/deadhand/Zotero/storage/QPDPKTE5/Tennant et al. - 2007 - The Warwick-Edinburgh Mental Well-being Scale (WEM.pdf:application/pdf;Snapshot:/home/deadhand/Zotero/storage/SSQDZGDV/1477-7525-5-63.html:text/html;Tennant et al_2007_The Warwick-Edinburgh Mental Well-being Scale (WEMWBS).pdf:/home/deadhand/Zotero/storage/XSKBHJPH/Tennant et al_2007_The Warwick-Edinburgh Mental Well-being Scale (WEMWBS).pdf:application/pdf;The Warwick-Edinburgh Mental Well-being Scale (WEMWBS)\: development and UK validation:/home/deadhand/Zotero/storage/RS6R7R2E/tennant2007.pdf.pdf:application/pdf},
}

@article{baer_using_2006,
	title = {Using self-report assessment methods to explore facets of mindfulness},
	volume = {13},
	issn = {1073-1911},
	doi = {10.1177/1073191105283504},
	abstract = {The authors examine the facet structure of mindfulness using five recently developed mindfulness questionnaires. Two large samples of undergraduate students completed mindfulness questionnaires and measures of other constructs. Psychometric properties of the mindfulness questionnaires were examined, including internal consistency and convergent and discriminant relationships with other variables. Factor analyses of the combined pool of items from the mindfulness questionnaires suggested that collectively they contain five clear, interpretable facets of mindfulness. Hierarchical confirmatory factor analyses suggested that at least four of the identified factors are components of an overall mindfulness construct and that the factor structure of mindfulness may vary with meditation experience. Mindfulness facets were shown to be differentially correlated in expected ways with several other constructs and to have incremental validity in the prediction of psychological symptoms. Findings suggest that conceptualizing mindfulness as a multifaceted construct is helpful in understanding its components and its relationships with other variables.},
	language = {eng},
	number = {1},
	journal = {Assessment},
	author = {Baer, Ruth A. and Smith, Gregory T. and Hopkins, Jaclyn and Krietemeyer, Jennifer and Toney, Leslie},
	month = mar,
	year = {2006},
	pmid = {16443717},
	keywords = {Humans, Female, Male, Attitude, Adult, Factor Analysis, Statistical, Middle Aged, Psychometrics, Reproducibility of Results, Surveys and Questionnaires, Adolescent, Cognition, Meditation},
	pages = {27--45},
	file = {Baer et al_2006_Using self-report assessment methods to explore facets of mindfulness.pdf:/home/deadhand/Zotero/storage/MXR7C7VM/Baer et al_2006_Using self-report assessment methods to explore facets of mindfulness.pdf:application/pdf;Using self-report assessment methods to explore facets of mindfulness:/home/deadhand/Zotero/storage/TME243BM/baer2006.pdf.pdf:application/pdf},
}

@article{lafontaine_selecting_2015,
	title = {Selecting the {Best} {Items} for a {Short}-{Form} of the {Experiences} in {Close} {Relationships} {Questionnaire}.},
	doi = {10.1037/t51913-000},
	abstract = {Five studies were conducted to develop a short form of the Experiences in Close Relationships (ECR) questionnaire with optimal psychometric properties. Study 1 involved Item Response Theory (IRT) analyses of the responses of 2,066 adults, resulting in a 12-item form of the ECR containing the most discriminating items. The psychometric properties of the ECR-12 were further demonstrated in two longitudinal studies of community samples of couples (Studies 2 and 3), in a sample of individuals in same-sex relationships (Study 4), and with couples seeking therapy (Study 5). The psychometric properties of the ECR-12 are as good as those of the original ECR and superior to those of an existing short form. The ECR-12 can confidently be used by researchers and mental health practitioners when a short measure of attachment anxiety and avoidance is required.},
	journal = {European Journal of Psychological Assessment},
	author = {Lafontaine, Marie-France and Brassard, Audrey and Lussier, Yvan and Valois, Pierre and Shaver, Phillip and Johnson, Susan},
	month = jan,
	year = {2015},
	file = {Lafontaine et al_2015_Selecting the Best Items for a Short-Form of the Experiences in Close.pdf:/home/deadhand/Zotero/storage/8LUPIASS/Lafontaine et al_2015_Selecting the Best Items for a Short-Form of the Experiences in Close.pdf:application/pdf},
}

@misc{terrence_answer_2021,
	title = {Answer to "{CFA} in {R}: {The} variance-covariance matrix of the estimated parameters (vcov) does not appear to be positive definite"},
	shorttitle = {Answer to "{CFA} in {R}},
	url = {https://stackoverflow.com/a/69930089},
	urldate = {2022-09-16},
	journal = {Stack Overflow},
	author = {Terrence},
	month = nov,
	year = {2021},
	file = {Snapshot:/home/deadhand/Zotero/storage/UPQMTHZ4/cfa-in-r-the-variance-covariance-matrix-of-the-estimated-parameters-vcov-does.html:text/html},
}

@article{henry_short-form_2005,
	title = {The short-form version of the {Depression} {Anxiety} {Stress} {Scales} ({DASS}-21): construct validity and normative data in a large non-clinical sample},
	volume = {44},
	issn = {0144-6657},
	shorttitle = {The short-form version of the {Depression} {Anxiety} {Stress} {Scales} ({DASS}-21)},
	doi = {10.1348/014466505X29657},
	abstract = {OBJECTIVES: To test the construct validity of the short-form version of the Depression anxiety and stress scale (DASS-21), and in particular, to assess whether stress as indexed by this measure is synonymous with negative affectivity (NA) or whether it represents a related, but distinct, construct. To provide normative data for the general adult population.
DESIGN: Cross-sectional, correlational and confirmatory factor analysis (CFA).
METHODS: The DASS-21 was administered to a non-clinical sample, broadly representative of the general adult UK population (N = 1,794). Competing models of the latent structure of the DASS-21 were evaluated using CFA.
RESULTS: The model with optimal fit (RCFI = 0.94) had a quadripartite structure, and consisted of a general factor of psychological distress plus orthogonal specific factors of depression, anxiety, and stress. This model was a significantly better fit than a competing model that tested the possibility that the Stress scale simply measures NA.
CONCLUSIONS: The DASS-21 subscales can validly be used to measure the dimensions of depression, anxiety, and stress. However, each of these subscales also taps a more general dimension of psychological distress or NA. The utility of the measure is enhanced by the provision of normative data based on a large sample.},
	language = {eng},
	number = {Pt 2},
	journal = {The British Journal of Clinical Psychology},
	author = {Henry, Julie D. and Crawford, John R.},
	month = jun,
	year = {2005},
	pmid = {16004657},
	keywords = {Humans, Female, Male, Adult, Factor Analysis, Statistical, Middle Aged, Reproducibility of Results, Surveys and Questionnaires, Adolescent, Aged, Aged, 80 and over, Anxiety, Affect, Cross-Sectional Studies, Depression, Severity of Illness Index, Stress, Psychological},
	pages = {227--239},
	file = {Henry_Crawford_2005_The short-form version of the Depression Anxiety Stress Scales (DASS-21).pdf:/home/deadhand/Zotero/storage/JRZCULWJ/Henry_Crawford_2005_The short-form version of the Depression Anxiety Stress Scales (DASS-21).pdf:application/pdf;The short-form version of the Depression Anxiety Stress Scales (DASS-21)\: construct validity and normative data in a large non-clinical sample:/home/deadhand/Zotero/storage/U45BWSJW/henry2005.pdf.pdf:application/pdf},
}

@article{norton_depression_2007,
	title = {Depression {Anxiety} and {Stress} {Scales} ({DASS}-21): {Psychometric} analysis across four racial groups},
	volume = {20},
	issn = {1061-5806},
	shorttitle = {Depression {Anxiety} and {Stress} {Scales} ({DASS}-21)},
	url = {https://doi.org/10.1080/10615800701309279},
	doi = {10.1080/10615800701309279},
	abstract = {Growing cross-cultural awareness has led researchers to examine frequently used research instruments and assessment tools in racially diverse populations. The present study was conducted to assess the psychometric characteristics of the 21-item version of the Depression, Anxiety, and Stress Scales (DASS-21) among different racial groups. The DASS-21 was chosen because it appears to be a reliable and easy to administer measure, ideal for both clinical and research purposes. Results suggest that the internal consistency, and convergent and divergent validity of the DASS-21 are similar across racial groups. Multigroup CFA, however, indicated that item loadings were invariant, while scale covariances were not invariant. This suggests that, although the items may load similarly on the depression, anxiety and stress constructs, these constructs may be differentially inter-related across groups. Implications for application in clinical practice are discussed.},
	number = {3},
	urldate = {2022-09-16},
	journal = {Anxiety, Stress, \& Coping},
	author = {Norton, Peter J.},
	month = sep,
	year = {2007},
	pmid = {17999228},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10615800701309279},
	keywords = {Depression, anxiety, cross-cultural, psychometric, stress},
	pages = {253--265},
	file = {Depression Anxiety and Stress Scales (DASS-21)\: Psychometric analysis across four racial groups:/home/deadhand/Zotero/storage/75W8LCQH/norton2007.pdf.pdf:application/pdf;Norton_2007_Depression Anxiety and Stress Scales (DASS-21).pdf:/home/deadhand/Zotero/storage/EVNBT3M8/Norton_2007_Depression Anxiety and Stress Scales (DASS-21).pdf:application/pdf},
}

@article{lavaan,
	title = {{\textbraceleft}lavaan{\textbraceright}: An {\textbraceleft}R{\textbraceright} Package for Structural Equation Modeling},
	author = {Rosseel, Yves},
	year = {2012},
	date = {2012},
	volume = {48},
	doi = {10.18637/jss.v048.i02}
}

@article{semTools,
	title = {\texttt{\textbraceleft}semTools{\textbraceright}: {\textbraceleft}U{\textbraceright}seful tools for structural equation modeling},
	author = {Jorgensen, Terrence D. and Pornprasertmanit, Sunthud and Schoemann, Alexander M. and Rosseel, Yves},
	year = {2022},
	date = {2022},
	url = {https://CRAN.R-project.org/package=semTools}
}

@misc{psychci,
	title = {psych citation info},
	url = {https://cran.r-project.org/web/packages/psych/citation.html}
}
